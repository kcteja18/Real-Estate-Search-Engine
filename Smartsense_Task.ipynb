{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Floor plan detector"
      ],
      "metadata": {
        "id": "jz2jyP9iyuYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "TRAINING PIPELINE FOR FLOORPLAN OBJECT DETECTION FROM SCRATCH\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "import warnings\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Subset, SequentialSampler\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from torchvision.ops import box_iou, batched_nms\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "llRQi0Mt80JC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG = {\n",
        "    'dataset': {\n",
        "        'image_dir': '/content/drive/MyDrive/assets/train',\n",
        "        'annotation_file': '/content/drive/MyDrive/annotations.coco.json',\n",
        "        'train_split': 0.80,\n",
        "        'val_split': 0.10,\n",
        "    },\n",
        "    'training': {\n",
        "        'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "        'batch_size': 4,\n",
        "        'num_epochs': 50,\n",
        "        'learning_rate': 1e-4,\n",
        "        'weight_decay': 1e-4,\n",
        "        'warmup_epochs': 5,\n",
        "        'early_stopping_patience': 15,\n",
        "    },\n",
        "    'model': {\n",
        "        'num_fg_classes': 8,\n",
        "        'num_anchors': 9,\n",
        "        'image_size': 640,\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "zrUn4kf1859J"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class COCOFloorplanDataset:\n",
        "    def __init__(self, image_dir, annotation_file, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "        with open(annotation_file, 'r') as f:\n",
        "            self.coco_data = json.load(f)\n",
        "        self.images = self.coco_data['images']\n",
        "        self.annotations = self.coco_data['annotations']\n",
        "        self.img_to_anns = defaultdict(list)\n",
        "        for ann in self.annotations:\n",
        "            self.img_to_anns[ann['image_id']].append(ann)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_info = self.images[idx]\n",
        "        img_id = img_info['id']\n",
        "        img_path = os.path.join(self.image_dir, img_info['file_name'])\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        anns = self.img_to_anns[img_id]\n",
        "        boxes, labels = [], []\n",
        "        for ann in anns:\n",
        "            x, y, w, h = ann['bbox']\n",
        "            boxes.append([x, y, x + w, y + h])\n",
        "            labels.append(ann['category_id'])\n",
        "        if not boxes:\n",
        "            boxes = np.empty((0, 4), dtype=np.float32)\n",
        "            labels = np.empty((0,), dtype=np.int64)\n",
        "        else:\n",
        "            boxes = np.array(boxes, dtype=np.float32)\n",
        "            labels = np.array(labels, dtype=np.int64)\n",
        "        targets = {'boxes': boxes, 'labels': labels, 'image_id': img_id}\n",
        "        if self.transform:\n",
        "            image, targets = self.transform(image, targets)\n",
        "        return image, targets\n",
        "\n",
        "def collate_fn(batch):\n",
        "    images = [item[0] for item in batch]\n",
        "    targets = [item[1] for item in batch]\n",
        "    images = torch.stack(images, 0)\n",
        "    return images, targets"
      ],
      "metadata": {
        "id": "EMQf0mNp8_K8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FloorplanAugmentation:\n",
        "    def __init__(self, train=True, target_size=640):\n",
        "        self.train = train\n",
        "        self.target_size = target_size\n",
        "\n",
        "    def __call__(self, image, targets):\n",
        "        image = np.array(image)\n",
        "        height, width = image.shape[:2]\n",
        "        boxes = targets['boxes'].copy()\n",
        "\n",
        "        if self.train:\n",
        "            if random.random() < 0.5:\n",
        "                image = cv2.flip(image, 1)\n",
        "                if len(boxes) > 0:\n",
        "                    boxes_copy = boxes.copy()\n",
        "                    boxes[:, 0] = width - boxes_copy[:, 2]\n",
        "                    boxes[:, 2] = width - boxes_copy[:, 0]\n",
        "\n",
        "            if random.random() < 0.3:\n",
        "                image = cv2.flip(image, 0)\n",
        "                if len(boxes) > 0:\n",
        "                    boxes_copy = boxes.copy()\n",
        "                    boxes[:, 1] = height - boxes_copy[:, 3]\n",
        "                    boxes[:, 3] = height - boxes_copy[:, 1]\n",
        "\n",
        "            if random.random() < 0.5:\n",
        "                brightness = random.uniform(0.8, 1.2)\n",
        "                contrast = random.uniform(0.8, 1.2)\n",
        "                image = cv2.convertScaleAbs(image, alpha=contrast, beta=brightness)\n",
        "\n",
        "        scale_x = self.target_size / width\n",
        "        scale_y = self.target_size / height\n",
        "        image = cv2.resize(image, (self.target_size, self.target_size))\n",
        "\n",
        "        if len(boxes) > 0:\n",
        "            boxes[:, 0] *= scale_x\n",
        "            boxes[:, 2] *= scale_x\n",
        "            boxes[:, 1] *= scale_y\n",
        "            boxes[:, 3] *= scale_y\n",
        "            boxes[:, 0::2] = np.clip(boxes[:, 0::2], 0, self.target_size)\n",
        "            boxes[:, 1::2] = np.clip(boxes[:, 1::2], 0, self.target_size)\n",
        "\n",
        "        targets['boxes'] = boxes\n",
        "        image = image.astype(np.float32) / 255.0\n",
        "        image = torch.from_numpy(image).permute(2, 0, 1)\n",
        "\n",
        "        targets['boxes'] = torch.as_tensor(targets['boxes'], dtype=torch.float32)\n",
        "        targets['labels'] = torch.as_tensor(targets['labels'], dtype=torch.int64)\n",
        "        targets['image_id'] = torch.as_tensor(targets['image_id'], dtype=torch.int64)\n",
        "        if 'area' in targets:\n",
        "            targets['area'] = torch.as_tensor(targets['area'], dtype=torch.float32)\n",
        "\n",
        "        return image, targets"
      ],
      "metadata": {
        "id": "rdAJHoiN9KEa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleBackbone(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(64, 64, 2)\n",
        "        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n",
        "        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n",
        "\n",
        "    def _make_layer(self, in_channels, out_channels, blocks, stride=1):\n",
        "        layers = [\n",
        "            nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        ]\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(nn.Conv2d(out_channels, out_channels, 3, padding=1))\n",
        "            layers.append(nn.BatchNorm2d(out_channels))\n",
        "            layers.append(nn.ReLU(inplace=True))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.max_pool2d(x, kernel_size=3, stride=2, padding=1)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        return x\n",
        "\n",
        "class ObjectDetectorFromScratch(nn.Module):\n",
        "    def __init__(self, num_fg_classes=8, num_anchors=9, target_size=640):\n",
        "        super().__init__()\n",
        "        self.backbone = SimpleBackbone()\n",
        "        self.num_fg_classes = num_fg_classes\n",
        "        self.num_classes = num_fg_classes + 1\n",
        "        self.num_anchors = num_anchors\n",
        "        self.conv_head = nn.Conv2d(256, 256, 3, padding=1)\n",
        "        self.cls_logits = nn.Conv2d(256, num_anchors * self.num_classes, 1)\n",
        "        self.bbox_pred = nn.Conv2d(256, num_anchors * 4, 1)\n",
        "        self.feature_map_size = 40\n",
        "        self.stride = target_size / self.feature_map_size\n",
        "        self.anchor_scales = [1.0, 1.5, 2.0]\n",
        "        self.aspect_ratios = [0.5, 1.0, 2.0]\n",
        "        self.pos_thresh = 0.5\n",
        "        self.neg_thresh = 0.4\n",
        "        anchors = self._generate_anchors(target_size)\n",
        "        self.register_buffer(\"anchors\", anchors)\n",
        "\n",
        "    def _generate_anchors(self, target_size):\n",
        "        scales = torch.tensor(self.anchor_scales)\n",
        "        ratios = torch.tensor(self.aspect_ratios)\n",
        "        grid_x = (torch.arange(0, self.feature_map_size) + 0.5) * self.stride\n",
        "        grid_y = (torch.arange(0, self.feature_map_size) + 0.5) * self.stride\n",
        "        y_c, x_c = torch.meshgrid(grid_y, grid_x, indexing='ij')\n",
        "        centers = torch.stack([x_c, y_c], dim=-1).float().view(-1, 1, 2)\n",
        "        base_anchors_wh = []\n",
        "        for scale in scales:\n",
        "             for ratio in ratios:\n",
        "                base_size = self.stride * scale\n",
        "                w = base_size * torch.sqrt(ratio)\n",
        "                h = base_size / torch.sqrt(ratio)\n",
        "                base_anchors_wh.append([w, h])\n",
        "        base_anchors_wh = torch.tensor(base_anchors_wh).float()\n",
        "        centers_wh = torch.cat([centers.expand(-1, self.num_anchors, -1),\n",
        "                                base_anchors_wh.expand(self.feature_map_size**2, -1, -1)], dim=-1)\n",
        "        all_anchors_ctr = centers_wh.view(-1, 4)\n",
        "        x1y1 = all_anchors_ctr[:, :2] - all_anchors_ctr[:, 2:] / 2\n",
        "        x2y2 = all_anchors_ctr[:, :2] + all_anchors_ctr[:, 2:] / 2\n",
        "        return torch.cat([x1y1, x2y2], dim=-1).clamp(0, target_size)\n",
        "\n",
        "    def _encode_boxes(self, anchors, gt_boxes):\n",
        "        eps = 1e-6\n",
        "        anchors_wh = anchors[:, 2:] - anchors[:, :2]\n",
        "        anchors_ctr = anchors[:, :2] + 0.5 * anchors_wh\n",
        "        gt_wh = gt_boxes[:, 2:] - gt_boxes[:, :2]\n",
        "        gt_ctr = gt_boxes[:, :2] + 0.5 * gt_wh\n",
        "        tx = (gt_ctr[:, 0] - anchors_ctr[:, 0]) / (anchors_wh[:, 0] + eps)\n",
        "        ty = (gt_ctr[:, 1] - anchors_ctr[:, 1]) / (anchors_wh[:, 1] + eps)\n",
        "        tw = torch.log((gt_wh[:, 0] / (anchors_wh[:, 0] + eps)) + eps)\n",
        "        th = torch.log((gt_wh[:, 1] / (anchors_wh[:, 1] + eps)) + eps)\n",
        "        return torch.stack([tx, ty, tw, th], dim=1)\n",
        "\n",
        "    def _decode_boxes(self, anchors, deltas):\n",
        "        anchors_wh = anchors[:, 2:] - anchors[:, :2]\n",
        "        anchors_ctr = anchors[:, :2] + 0.5 * anchors_wh\n",
        "        pred_ctr_x = deltas[:, 0] * anchors_wh[:, 0] + anchors_ctr[:, 0]\n",
        "        pred_ctr_y = deltas[:, 1] * anchors_wh[:, 1] + anchors_ctr[:, 1]\n",
        "        pred_w = torch.exp(deltas[:, 2]) * anchors_wh[:, 0]\n",
        "        pred_h = torch.exp(deltas[:, 3]) * anchors_wh[:, 1]\n",
        "        x1 = pred_ctr_x - 0.5 * pred_w\n",
        "        y1 = pred_ctr_y - 0.5 * pred_h\n",
        "        x2 = pred_ctr_x + 0.5 * pred_w\n",
        "        y2 = pred_ctr_y + 0.5 * pred_h\n",
        "        return torch.stack([x1, y1, x2, y2], dim=1)\n",
        "\n",
        "    def forward(self, images, targets=None):\n",
        "        features = self.backbone(images)\n",
        "        x = F.relu(self.conv_head(features))\n",
        "        cls_logits = self.cls_logits(x)\n",
        "        bbox_deltas = self.bbox_pred(x)\n",
        "        batch_size = images.size(0)\n",
        "        cls_logits = cls_logits.permute(0, 2, 3, 1).contiguous().view(batch_size, -1, self.num_classes)\n",
        "        bbox_deltas = bbox_deltas.permute(0, 2, 3, 1).contiguous().view(batch_size, -1, 4)\n",
        "        if self.training:\n",
        "            if targets is None: raise ValueError(\"Targets needed for training.\")\n",
        "            return {'loss': self._compute_loss(cls_logits, bbox_deltas, targets)}\n",
        "        return self._generate_proposals(cls_logits, bbox_deltas)\n",
        "\n",
        "    def _compute_loss(self, cls_logits, bbox_deltas, targets):\n",
        "        batch_size = cls_logits.size(0)\n",
        "        anchors = self.anchors\n",
        "        all_cls_targets, all_reg_targets, all_reg_masks = [], [], []\n",
        "        for i in range(batch_size):\n",
        "            gt_boxes = targets[i]['boxes']\n",
        "            gt_labels = targets[i]['labels']\n",
        "            num_anchors = anchors.size(0)\n",
        "            if gt_boxes.numel() == 0:\n",
        "                cls_target = torch.full((num_anchors,), 0, dtype=torch.long, device=cls_logits.device)\n",
        "                reg_target = torch.zeros((num_anchors, 4), dtype=torch.float, device=cls_logits.device)\n",
        "                reg_mask = torch.zeros((num_anchors,), dtype=torch.bool, device=cls_logits.device)\n",
        "            else:\n",
        "                iou = box_iou(anchors, gt_boxes)\n",
        "                max_iou, max_iou_indices = iou.max(dim=1)\n",
        "                cls_target = torch.full((num_anchors,), -1, dtype=torch.long, device=cls_logits.device)\n",
        "                reg_target = torch.zeros((num_anchors, 4), dtype=torch.float, device=cls_logits.device)\n",
        "                cls_target[max_iou < self.neg_thresh] = 0\n",
        "                pos_mask = max_iou >= self.pos_thresh\n",
        "                cls_target[pos_mask] = gt_labels[max_iou_indices[pos_mask]]\n",
        "                gt_max_iou, gt_max_iou_indices = iou.max(dim=0)\n",
        "                if gt_max_iou.numel() > 0:\n",
        "                    cls_target[gt_max_iou_indices] = gt_labels\n",
        "                    pos_mask[gt_max_iou_indices] = True\n",
        "                reg_mask = pos_mask\n",
        "                if pos_mask.sum() > 0:\n",
        "                    reg_target[pos_mask] = self._encode_boxes(anchors[pos_mask], gt_boxes[max_iou_indices[pos_mask]])\n",
        "            all_cls_targets.append(cls_target)\n",
        "            all_reg_targets.append(reg_target)\n",
        "            all_reg_masks.append(reg_mask)\n",
        "        cls_targets = torch.cat(all_cls_targets)\n",
        "        reg_targets = torch.cat(all_reg_targets)\n",
        "        reg_masks = torch.cat(all_reg_masks)\n",
        "        cls_logits = cls_logits.view(-1, self.num_classes)\n",
        "        bbox_deltas = bbox_deltas.view(-1, 4)\n",
        "        cls_mask = cls_targets >= 0\n",
        "        loss_cls = F.cross_entropy(cls_logits[cls_mask], cls_targets[cls_mask], reduction='mean')\n",
        "        num_pos = reg_masks.sum()\n",
        "        loss_reg = F.smooth_l1_loss(bbox_deltas[reg_masks], reg_targets[reg_masks], beta=1.0, reduction='sum') / num_pos if num_pos > 0 else torch.tensor(0.0, device=cls_logits.device)\n",
        "        return loss_cls + loss_reg\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _generate_proposals(self, cls_logits, bbox_deltas, conf_thresh=0.05, nms_thresh=0.45):\n",
        "        batch_size = cls_logits.size(0)\n",
        "        anchors = self.anchors\n",
        "        scores = F.softmax(cls_logits, dim=-1)\n",
        "        detections = []\n",
        "        for i in range(batch_size):\n",
        "            pred_boxes = self._decode_boxes(anchors, bbox_deltas[i])\n",
        "            scores_fg = scores[i][:, 1:]\n",
        "            top_scores, top_labels = scores_fg.max(dim=1)\n",
        "            keep = top_scores > conf_thresh\n",
        "            boxes_out, scores_out, labels_out = pred_boxes[keep], top_scores[keep], top_labels[keep] + 1\n",
        "            if boxes_out.numel() == 0:\n",
        "                detections.append({'boxes': torch.empty(0, 4), 'scores': torch.empty(0), 'labels': torch.empty(0, dtype=torch.long)})\n",
        "                continue\n",
        "            keep_nms = batched_nms(boxes_out, scores_out, labels_out, nms_thresh)\n",
        "            detections.append({'boxes': boxes_out[keep_nms], 'scores': scores_out[keep_nms], 'labels': labels_out[keep_nms]})\n",
        "        return detections"
      ],
      "metadata": {
        "id": "7VYsYHCe9Ole"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_iou(box1, box2):\n",
        "    # Use standard torchvision for speed and correctness if possible\n",
        "    if isinstance(box1, np.ndarray): box1 = torch.tensor(box1)\n",
        "    if isinstance(box2, np.ndarray): box2 = torch.tensor(box2)\n",
        "    return box_iou(box1.unsqueeze(0) if box1.ndim==1 else box1,\n",
        "                   box2.unsqueeze(0) if box2.ndim==1 else box2).squeeze()\n",
        "\n",
        "def compute_ap(predictions, ground_truth, iou_threshold=0.5):\n",
        "    if len(predictions) == 0: return 0.0\n",
        "    if len(ground_truth) == 0: return 0.0\n",
        "    predictions = sorted(predictions, key=lambda x: x['score'], reverse=True)\n",
        "    tp, fp = np.zeros(len(predictions)), np.zeros(len(predictions))\n",
        "    gt_matched = set()\n",
        "    for i, pred in enumerate(predictions):\n",
        "        # Use torchvision box_iou for efficiency\n",
        "        iou = box_iou(torch.tensor([pred['box']]), torch.tensor(ground_truth)).squeeze(0)\n",
        "        if iou.numel() > 0:\n",
        "            best_iou, best_gt_idx = iou.max(dim=0)\n",
        "            best_iou, best_gt_idx = best_iou.item(), best_gt_idx.item()\n",
        "        else:\n",
        "             best_iou, best_gt_idx = 0, -1\n",
        "\n",
        "        if best_iou >= iou_threshold:\n",
        "            if best_gt_idx not in gt_matched:\n",
        "                tp[i] = 1\n",
        "                gt_matched.add(best_gt_idx)\n",
        "            else: fp[i] = 1\n",
        "        else: fp[i] = 1\n",
        "    tp_cumsum, fp_cumsum = np.cumsum(tp), np.cumsum(fp)\n",
        "    recalls = tp_cumsum / len(ground_truth)\n",
        "    precisions = tp_cumsum / (tp_cumsum + fp_cumsum + 1e-6)\n",
        "    ap = 0\n",
        "    for t in np.arange(0, 1.1, 0.1):\n",
        "        ap += (np.max(precisions[recalls >= t]) if np.sum(recalls >= t) > 0 else 0) / 11\n",
        "    return ap"
      ],
      "metadata": {
        "id": "Vr0NXkvD912m"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, dataloader, optimizer, device, epoch, num_epochs, warmup_epochs, base_lr):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    if epoch < warmup_epochs:\n",
        "        lr = base_lr * (epoch + 1) / warmup_epochs\n",
        "        for param_group in optimizer.param_groups: param_group['lr'] = lr\n",
        "    else: lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "    loader = tqdm(dataloader, desc=f\"Epoch {epoch}/{num_epochs} [Train]\")\n",
        "    for images, targets in loader:\n",
        "        images = images.to(device)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        optimizer.zero_grad()\n",
        "        loss = model(images, targets)['loss']\n",
        "        if not torch.isfinite(loss): continue\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        loader.set_postfix(loss=loss.item(), lr=lr)\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, dataloader, device, num_fg_classes):\n",
        "    total_val_loss = 0\n",
        "    all_preds_by_class = defaultdict(list)\n",
        "    all_gts_by_class = defaultdict(list)\n",
        "    ious_for_miou = [] # List to store IoUs of matched detections\n",
        "\n",
        "    loader = tqdm(dataloader, desc=\"Evaluating\")\n",
        "    for images, targets in loader:\n",
        "        images = images.to(device)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        # 1. Get Loss\n",
        "        model.train()\n",
        "        total_val_loss += model(images, targets)['loss'].item()\n",
        "\n",
        "        # 2. Get Predictions\n",
        "        model.eval()\n",
        "        predictions = model(images)\n",
        "\n",
        "        for i, (pred_dict, gt_dict) in enumerate(zip(predictions, targets)):\n",
        "            # --- mIoU Calculation ---\n",
        "            if len(pred_dict['boxes']) > 0 and len(gt_dict['boxes']) > 0:\n",
        "                 # Calculate IoU for ALL predictions against ALL GTs in this image\n",
        "                 iou_matrix = box_iou(pred_dict['boxes'], gt_dict['boxes'])\n",
        "                 # For each prediction, find its BEST matching GT\n",
        "                 max_ious, _ = iou_matrix.max(dim=1)\n",
        "                 # Only consider \"reasonable\" detections (e.g. IoU > 0.5) for the Average IoU metric\n",
        "                 # to avoid dragging down the score with obvious false positives.\n",
        "                 # This gives \"Average IoU of True Positives\".\n",
        "                 valid_ious = max_ious[max_ious > 0.5]\n",
        "                 if valid_ious.numel() > 0:\n",
        "                     ious_for_miou.extend(valid_ious.cpu().tolist())\n",
        "\n",
        "            # --- Data for mAP ---\n",
        "            for cls_id in range(1, num_fg_classes + 1):\n",
        "                gt_mask = gt_dict['labels'] == cls_id\n",
        "                all_gts_by_class[cls_id].extend(gt_dict['boxes'][gt_mask].cpu())\n",
        "                pred_mask = pred_dict['labels'] == cls_id\n",
        "                for box, score in zip(pred_dict['boxes'][pred_mask], pred_dict['scores'][pred_mask]):\n",
        "                    all_preds_by_class[cls_id].append({'box': box.cpu().numpy(), 'score': score.cpu().item()})\n",
        "\n",
        "    ap_per_class = [compute_ap(all_preds_by_class[c], np.array(all_gts_by_class[c])) for c in range(1, num_fg_classes + 1)]\n",
        "    # Calculate mean of collected IoUs\n",
        "    mIoU = np.mean(ious_for_miou) if len(ious_for_miou) > 0 else 0.0\n",
        "\n",
        "    return total_val_loss / len(dataloader), np.mean(ap_per_class), mIoU"
      ],
      "metadata": {
        "id": "UdBbVe7x97WW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainingTracker:\n",
        "    def __init__(self):\n",
        "        self.history = {'train_loss': [], 'val_loss': [], 'val_mAP': [], 'val_mIoU': [], 'learning_rate': []}\n",
        "        self.best_val_mAP = 0.0\n",
        "        self.patience_counter = 0\n",
        "\n",
        "    def update(self, epoch, train_loss, val_loss, val_mAP, val_mIoU, lr):\n",
        "        self.history['train_loss'].append(train_loss)\n",
        "        self.history['val_loss'].append(val_loss)\n",
        "        self.history['val_mAP'].append(val_mAP)\n",
        "        self.history['val_mIoU'].append(val_mIoU)\n",
        "        self.history['learning_rate'].append(lr)\n",
        "        if val_mAP > self.best_val_mAP:\n",
        "            self.best_val_mAP = val_mAP\n",
        "            self.patience_counter = 0\n",
        "            return 0, True\n",
        "        self.patience_counter += 1\n",
        "        return self.patience_counter, False\n",
        "\n",
        "    def print_epoch(self, epoch, train_loss, val_loss, val_mAP, val_mIoU, lr):\n",
        "        print(f\"Epoch {epoch:3d} | TrnLoss: {train_loss:.4f} | ValLoss: {val_loss:.4f} | \"\n",
        "              f\"mAP: {val_mAP:.4f} | mIoU: {val_mIoU:.4f} | LR: {lr:.2e}\")"
      ],
      "metadata": {
        "id": "d2HRYeuO-Bby"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.device = torch.device(config['training']['device'])\n",
        "        self.tracker = TrainingTracker()\n",
        "        self.model = ObjectDetectorFromScratch(\n",
        "            num_fg_classes=config['model']['num_fg_classes'],\n",
        "            num_anchors=config['model']['num_anchors'],\n",
        "            target_size=config['model']['image_size']\n",
        "        ).to(self.device)\n",
        "        self.train_loader, self.val_loader = self._setup_dataloaders()\n",
        "        self.optimizer = optim.AdamW(self.model.parameters(), lr=config['training']['learning_rate'], weight_decay=config['training']['weight_decay'])\n",
        "        self.scheduler = CosineAnnealingLR(self.optimizer, T_max=config['training']['num_epochs'] - config['training']['warmup_epochs'], eta_min=1e-6)\n",
        "\n",
        "    def _setup_dataloaders(self):\n",
        "        train_tf = FloorplanAugmentation(train=True, target_size=self.config['model']['image_size'])\n",
        "        val_tf = FloorplanAugmentation(train=False, target_size=self.config['model']['image_size'])\n",
        "        train_ds = COCOFloorplanDataset(self.config['dataset']['image_dir'], self.config['dataset']['annotation_file'], train_tf)\n",
        "        val_ds = COCOFloorplanDataset(self.config['dataset']['image_dir'], self.config['dataset']['annotation_file'], val_tf)\n",
        "        indices = list(range(len(train_ds)))\n",
        "        random.shuffle(indices)\n",
        "        split = int(len(train_ds) * self.config['dataset']['train_split'])\n",
        "        print(f\"Dataset split: {split} train, {len(indices) - split} val\")\n",
        "        return (DataLoader(Subset(train_ds, indices[:split]), batch_size=self.config['training']['batch_size'], shuffle=True, num_workers=2, collate_fn=collate_fn, pin_memory=True),\n",
        "                DataLoader(Subset(val_ds, indices[split:]), batch_size=self.config['training']['batch_size'], shuffle=False, num_workers=2, collate_fn=collate_fn, pin_memory=True))\n",
        "\n",
        "    def train(self):\n",
        "        print(f\"\\nSTARTING TRAINING | Device: {self.device} | Params: {sum(p.numel() for p in self.model.parameters() if p.requires_grad):,}\")\n",
        "        cfg = self.config['training']\n",
        "        EVAL_EVERY = 5\n",
        "        for epoch in range(cfg['num_epochs']):\n",
        "            train_loss = train_one_epoch(self.model, self.train_loader, self.optimizer, self.device, epoch, cfg['num_epochs'], cfg['warmup_epochs'], cfg['learning_rate'])\n",
        "            if (epoch + 1) % EVAL_EVERY == 0 or epoch == cfg['num_epochs'] - 1:\n",
        "                val_loss, val_mAP, val_mIoU = evaluate(self.model, self.val_loader, self.device, self.config['model']['num_fg_classes'])\n",
        "                lr = self.optimizer.param_groups[0]['lr']\n",
        "                patience, is_best = self.tracker.update(epoch, train_loss, val_loss, val_mAP, val_mIoU, lr)\n",
        "                self.tracker.print_epoch(epoch, train_loss, val_loss, val_mAP, val_mIoU, lr)\n",
        "                if is_best:\n",
        "                    torch.save(self.model.state_dict(), 'best_model.pth')\n",
        "                    print(f\"  -> New best model (mAP: {val_mAP:.4f}, mIoU: {val_mIoU:.4f})\")\n",
        "                if patience >= cfg['early_stopping_patience']:\n",
        "                    print(f\"Early stopping at epoch {epoch}\"); break\n",
        "            else: print(f\"Epoch {epoch:3d} | Train Loss: {train_loss:.4f}\")\n",
        "            if epoch >= cfg['warmup_epochs']: self.scheduler.step()\n",
        "        torch.save(self.model.state_dict(), 'final_model.pth')\n",
        "        return self.tracker.history\n",
        "\n",
        "def main():\n",
        "    if CONFIG['training']['device'] == 'cpu': print(\"WARNING: Training on CPU will be slow.\")\n",
        "    if not Path(CONFIG['dataset']['image_dir']).exists() or not Path(CONFIG['dataset']['annotation_file']).exists():\n",
        "        print(\"Error: Dataset not found. Check paths in CONFIG.\"); return\n",
        "    trainer = Trainer(CONFIG)\n",
        "    trainer.train()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z69VjSSK-Err",
        "outputId": "4ce9bf7e-ed5f-4c57-e6d1-b755e70828c7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset split: 436 train, 109 val\n",
            "\n",
            "STARTING TRAINING | Device: cuda | Params: 1,812,085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0/50 [Train]: 100%|██████████| 109/109 [01:38<00:00,  1.11it/s, loss=0.721, lr=2e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   0 | Train Loss: 1.5445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/50 [Train]: 100%|██████████| 109/109 [00:08<00:00, 12.28it/s, loss=0.204, lr=4e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   1 | Train Loss: 0.3124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/50 [Train]: 100%|██████████| 109/109 [00:08<00:00, 13.42it/s, loss=0.118, lr=6e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   2 | Train Loss: 0.1804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/50 [Train]: 100%|██████████| 109/109 [00:08<00:00, 12.11it/s, loss=0.191, lr=8e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   3 | Train Loss: 0.1620\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/50 [Train]: 100%|██████████| 109/109 [00:07<00:00, 13.70it/s, loss=0.168, lr=0.0001]\n",
            "Evaluating: 100%|██████████| 28/28 [00:23<00:00,  1.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   4 | TrnLoss: 0.1372 | ValLoss: 0.1250 | mAP: 0.0194 | mIoU: 0.6504 | LR: 1.00e-04\n",
            "  -> New best model (mAP: 0.0194, mIoU: 0.6504)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/50 [Train]: 100%|██████████| 109/109 [00:09<00:00, 12.02it/s, loss=0.128, lr=0.0001]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   5 | Train Loss: 0.1263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/50 [Train]: 100%|██████████| 109/109 [00:09<00:00, 12.04it/s, loss=0.115, lr=9.99e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   6 | Train Loss: 0.1165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/50 [Train]: 100%|██████████| 109/109 [00:08<00:00, 13.58it/s, loss=0.143, lr=9.95e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   7 | Train Loss: 0.1089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/50 [Train]: 100%|██████████| 109/109 [00:09<00:00, 12.00it/s, loss=0.115, lr=9.89e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   8 | Train Loss: 0.0976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/50 [Train]: 100%|██████████| 109/109 [00:08<00:00, 13.15it/s, loss=0.109, lr=9.81e-5]\n",
            "Evaluating: 100%|██████████| 28/28 [00:03<00:00,  8.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   9 | TrnLoss: 0.0998 | ValLoss: 0.1009 | mAP: 0.0526 | mIoU: 0.6719 | LR: 9.81e-05\n",
            "  -> New best model (mAP: 0.0526, mIoU: 0.6719)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/50 [Train]: 100%|██████████| 109/109 [00:08<00:00, 13.47it/s, loss=0.103, lr=9.7e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  10 | Train Loss: 0.0919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/50 [Train]: 100%|██████████| 109/109 [00:09<00:00, 11.85it/s, loss=0.0924, lr=9.57e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  11 | Train Loss: 0.0844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/50 [Train]: 100%|██████████| 109/109 [00:08<00:00, 12.16it/s, loss=0.0742, lr=9.42e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  12 | Train Loss: 0.0779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/50 [Train]: 100%|██████████| 109/109 [00:08<00:00, 13.24it/s, loss=0.0641, lr=9.25e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  13 | Train Loss: 0.0763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/50 [Train]: 100%|██████████| 109/109 [00:09<00:00, 11.93it/s, loss=0.0702, lr=9.05e-5]\n",
            "Evaluating: 100%|██████████| 28/28 [00:02<00:00, 10.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  14 | TrnLoss: 0.0733 | ValLoss: 0.0884 | mAP: 0.0668 | mIoU: 0.6701 | LR: 9.05e-05\n",
            "  -> New best model (mAP: 0.0668, mIoU: 0.6701)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/50 [Train]: 100%|██████████| 109/109 [00:09<00:00, 11.81it/s, loss=0.0606, lr=8.84e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  15 | Train Loss: 0.0673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/50 [Train]: 100%|██████████| 109/109 [00:08<00:00, 13.46it/s, loss=0.043, lr=8.61e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  16 | Train Loss: 0.0650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/50 [Train]: 100%|██████████| 109/109 [00:09<00:00, 11.93it/s, loss=0.109, lr=8.36e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  17 | Train Loss: 0.0629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/50 [Train]: 100%|██████████| 109/109 [00:08<00:00, 12.41it/s, loss=0.0554, lr=8.1e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  18 | Train Loss: 0.0595\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/50 [Train]: 100%|██████████| 109/109 [00:08<00:00, 13.03it/s, loss=0.0395, lr=7.82e-5]\n",
            "Evaluating: 100%|██████████| 28/28 [00:02<00:00, 11.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  19 | TrnLoss: 0.0588 | ValLoss: 0.0821 | mAP: 0.0872 | mIoU: 0.6787 | LR: 7.82e-05\n",
            "  -> New best model (mAP: 0.0872, mIoU: 0.6787)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/50 [Train]: 100%|██████████| 109/109 [00:08<00:00, 12.75it/s, loss=0.0546, lr=7.53e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  20 | Train Loss: 0.0554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/50 [Train]: 100%|██████████| 109/109 [00:09<00:00, 11.99it/s, loss=0.0495, lr=7.22e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  21 | Train Loss: 0.0527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/50 [Train]: 100%|██████████| 109/109 [00:08<00:00, 13.50it/s, loss=0.0413, lr=6.9e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  22 | Train Loss: 0.0524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/50 [Train]: 100%|██████████| 109/109 [00:09<00:00, 11.82it/s, loss=0.0562, lr=6.58e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  23 | Train Loss: 0.0491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/50 [Train]: 100%|██████████| 109/109 [00:09<00:00, 11.66it/s, loss=0.053, lr=6.25e-5]\n",
            "Evaluating: 100%|██████████| 28/28 [00:02<00:00, 11.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  24 | TrnLoss: 0.0493 | ValLoss: 0.0792 | mAP: 0.1066 | mIoU: 0.6777 | LR: 6.25e-05\n",
            "  -> New best model (mAP: 0.1066, mIoU: 0.6777)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/50 [Train]: 100%|██████████| 109/109 [00:08<00:00, 12.52it/s, loss=0.0452, lr=5.91e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  25 | Train Loss: 0.0461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/50 [Train]: 100%|██████████| 109/109 [00:08<00:00, 12.96it/s, loss=0.0463, lr=5.57e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  26 | Train Loss: 0.0428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/50 [Train]: 100%|██████████| 109/109 [00:09<00:00, 12.05it/s, loss=0.0286, lr=5.22e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  27 | Train Loss: 0.0427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/50 [Train]: 100%|██████████| 109/109 [00:08<00:00, 13.30it/s, loss=0.0442, lr=4.88e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  28 | Train Loss: 0.0408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/50 [Train]: 100%|██████████| 109/109 [00:09<00:00, 12.01it/s, loss=0.0274, lr=4.53e-5]\n",
            "Evaluating: 100%|██████████| 28/28 [00:02<00:00, 11.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  29 | TrnLoss: 0.0392 | ValLoss: 0.0778 | mAP: 0.1066 | mIoU: 0.6797 | LR: 4.53e-05\n",
            "  -> New best model (mAP: 0.1066, mIoU: 0.6797)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/50 [Train]: 100%|██████████| 109/109 [00:09<00:00, 11.95it/s, loss=0.0383, lr=4.19e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  30 | Train Loss: 0.0370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31/50 [Train]: 100%|██████████| 109/109 [00:08<00:00, 12.37it/s, loss=0.0511, lr=3.85e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  31 | Train Loss: 0.0370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32/50 [Train]: 100%|██████████| 109/109 [00:08<00:00, 12.96it/s, loss=0.0297, lr=3.52e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  32 | Train Loss: 0.0343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33/50 [Train]: 100%|██████████| 109/109 [00:09<00:00, 11.99it/s, loss=0.0308, lr=3.2e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  33 | Train Loss: 0.0359\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34/50 [Train]: 100%|██████████| 109/109 [00:08<00:00, 13.26it/s, loss=0.0263, lr=2.88e-5]\n",
            "Evaluating: 100%|██████████| 28/28 [00:03<00:00,  7.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  34 | TrnLoss: 0.0337 | ValLoss: 0.0756 | mAP: 0.1096 | mIoU: 0.6824 | LR: 2.88e-05\n",
            "  -> New best model (mAP: 0.1096, mIoU: 0.6824)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35/50 [Train]: 100%|██████████| 109/109 [00:08<00:00, 13.58it/s, loss=0.0301, lr=2.58e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  35 | Train Loss: 0.0328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36/50 [Train]: 100%|██████████| 109/109 [00:09<00:00, 11.84it/s, loss=0.0466, lr=2.28e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  36 | Train Loss: 0.0311\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37/50 [Train]: 100%|██████████| 109/109 [00:08<00:00, 12.14it/s, loss=0.0476, lr=2e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  37 | Train Loss: 0.0307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38/50 [Train]: 100%|██████████| 109/109 [00:08<00:00, 13.14it/s, loss=0.0289, lr=1.74e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  38 | Train Loss: 0.0315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39/50 [Train]: 100%|██████████| 109/109 [00:09<00:00, 11.89it/s, loss=0.0244, lr=1.49e-5]\n",
            "Evaluating: 100%|██████████| 28/28 [00:02<00:00, 11.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  39 | TrnLoss: 0.0307 | ValLoss: 0.0742 | mAP: 0.1178 | mIoU: 0.6841 | LR: 1.49e-05\n",
            "  -> New best model (mAP: 0.1178, mIoU: 0.6841)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40/50 [Train]: 100%|██████████| 109/109 [00:09<00:00, 11.87it/s, loss=0.0232, lr=1.26e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  40 | Train Loss: 0.0278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41/50 [Train]: 100%|██████████| 109/109 [00:08<00:00, 13.45it/s, loss=0.0397, lr=1.05e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  41 | Train Loss: 0.0291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42/50 [Train]: 100%|██████████| 109/109 [00:09<00:00, 11.77it/s, loss=0.0253, lr=8.52e-6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  42 | Train Loss: 0.0279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43/50 [Train]: 100%|██████████| 109/109 [00:09<00:00, 11.98it/s, loss=0.0278, lr=6.79e-6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  43 | Train Loss: 0.0290\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44/50 [Train]: 100%|██████████| 109/109 [00:08<00:00, 13.16it/s, loss=0.0202, lr=5.28e-6]\n",
            "Evaluating: 100%|██████████| 28/28 [00:02<00:00, 10.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  44 | TrnLoss: 0.0280 | ValLoss: 0.0740 | mAP: 0.1175 | mIoU: 0.6854 | LR: 5.28e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45/50 [Train]: 100%|██████████| 109/109 [00:08<00:00, 12.94it/s, loss=0.0409, lr=3.99e-6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  45 | Train Loss: 0.0290\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46/50 [Train]: 100%|██████████| 109/109 [00:09<00:00, 11.87it/s, loss=0.0267, lr=2.92e-6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  46 | Train Loss: 0.0281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47/50 [Train]: 100%|██████████| 109/109 [00:08<00:00, 13.30it/s, loss=0.0228, lr=2.08e-6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  47 | Train Loss: 0.0277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 48/50 [Train]: 100%|██████████| 109/109 [00:09<00:00, 11.94it/s, loss=0.0388, lr=1.48e-6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  48 | Train Loss: 0.0274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49/50 [Train]: 100%|██████████| 109/109 [00:09<00:00, 11.57it/s, loss=0.0188, lr=1.12e-6]\n",
            "Evaluating: 100%|██████████| 28/28 [00:02<00:00, 11.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  49 | TrnLoss: 0.0276 | ValLoss: 0.0741 | mAP: 0.1187 | mIoU: 0.6853 | LR: 1.12e-06\n",
            "  -> New best model (mAP: 0.1187, mIoU: 0.6853)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RKK6jvDOvrKG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}